{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to TreatGeoSelf with gridded climate data set coordinates\n",
    "\n",
    "### Case study: the Sauk-Suiattle river watershed\n",
    "\n",
    "### Use this Jupyter Notebook to:\n",
    "    1. HydroShare setup and preparation\n",
    "    2. Retrieve a mapping file (contains gridded cell centroids) for the study site of interest\n",
    "    3. Retrieve a folder of datafiles that were previously obtained for the study site of interest\n",
    "    4. Remap the file directories for each gridded cell centroid in the mapping file\n",
    "\n",
    "<img src=\"http://www.sauk-suiattle.com/images/Elliott.jpg\" \n",
    "style=\"float:right;width:150px;padding:20px\">\n",
    "\n",
    "<br/><br/><br/>\n",
    "<img src=\"https://www.washington.edu/brand/files/2014/09/W-Logo_Purple_Hex.png\"\n",
    "style=\"float:right;width:150px;padding:20px\">\n",
    "\n",
    "<br/><br/>\n",
    "#### This data is compiled to digitally observe the watersheds, powered by HydroShare. <br/>Provided by the Watershed Dynamics Group, Dept. of Civil and Environmental Engineering, University of Washington"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  HydroShare setup and preparation\n",
    "\n",
    "To run this notebook, we must import several libaries. These are listed in order of 1) Python standard libraries, 2) hs_utils library provides functions for interacting with HydroShare, including resource querying, dowloading and creation, and 3) the observatory_gridded_hydromet library that is downloaded with this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the python library basemap-data-hires is not installed, please uncomment and run the following lines in terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "import os\n",
    "import ogh\n",
    "import tarfile\n",
    "\n",
    "# data migration library\n",
    "from utilities import hydroshare\n",
    "\n",
    "# silencing warning\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish a secure connection with HydroShare by instantiating the hydroshare class that is defined within hs_utils. In addition to connecting with HydroShare, this command also sets and prints environment variables for several parameters that will be useful for saving work back to HydroShare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hs=hydroshare.hydroshare()\n",
    "homedir = hs.getContentPath(os.environ[\"HS_RES_ID\"])\n",
    "os.chdir(homedir)\n",
    "print('Data will be loaded from and save to:'+homedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are curious about where the data is being downloaded, click on the Jupyter Notebook dashboard icon to return to the File System view.  The homedir directory location printed above is where you can find the data and contents you will download to a HydroShare JupyterHub server.  At the end of this work session, you can migrate this data to the HydroShare iRods server as a Generic Resource. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate a mapping file for the study site of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the files\n",
    "\n",
    "Here, we will retrieve two data objects then catalog the files within the mapping file. The Hydroshare resource 'https://www.hydroshare.org/resource/3629f2d5315b48fdb8eb851c1dd9ce63/' contains the mapping file for a test study site. The zipfolder contains the WRF ASCII files (described in Salathe et al. 2014) from a previous data download run, and may contain more files than is necessary for the study of our study site. \n",
    "\n",
    "First, we will need to migrate these objects into the computing environment, and designate their path directories. Then, we will unzip the zipfolder, then catalog the two data products into the mappingfile under two dataset names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sample mapping file and previously downloaded files\n",
    "\"\"\"\n",
    "# List of available data\n",
    "hs.getResourceFromHydroShare('3629f2d5315b48fdb8eb851c1dd9ce63')\n",
    "\n",
    "folderpath = hs.getContentPath('3629f2d5315b48fdb8eb851c1dd9ce63') # the folder\n",
    "mappingfile1 = os.path.abspath(hs.content['Sauk_mappingfile.csv']) # the mapping file in the folder\n",
    "zipfolder = os.path.abspath(hs.content['salathe2014.tar.gz']) # the zipfolder in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(folderpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip the tar.gz file to a folder of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = tarfile.open(zipfolder) \n",
    "tar.extractall(path=folderpath) # untar file into same directory\n",
    "tar.close()\n",
    "os.remove(zipfolder)\n",
    "\n",
    "os.listdir(folderpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the mapping file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapdf, nstations = ogh.mappingfileToDF(os.path.abspath(mappingfile1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Remap the file directories for each gridded cell centroid in the mapping file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider the help tool to understand the function and its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ogh.remapCatalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dailywrf_salathe2014\n",
    "ogh.remapCatalog(mappingfile=mappingfile1,\n",
    "                 catalog_label='dailywrf_salathe2014',\n",
    "                 homedir=folderpath,\n",
    "                 subdir='salathe2014/WWA_1950_2010/raw')\n",
    "\n",
    "# dailywrf_bcsalathe2014\n",
    "ogh.remapCatalog(mappingfile=mappingfile1,\n",
    "                 catalog_label='dailywrf_bcsalathe2014',\n",
    "                 homedir=folderpath,\n",
    "                 subdir='salathe2014/WWA_1950_2010/bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the mapping file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapdf, nstations = ogh.mappingfileToDF(os.path.abspath(mappingfile1))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
