{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Convert centroids to meshgrid\n",
    "\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/04.13-geographic-data-with-basemap.html\n",
    "http://bagrow.com/dsv/heatmap_basemap.html\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Fast Geospatial analytics with dask and geopandas\n",
    "\n",
    "http://matthewrocklin.com/blog/work/2017/09/21/accelerating-geopandas-1\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ogh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ogh.ogh_meta"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ogh.ogh_meta())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict(ogh.ogh_meta()))>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='test.json'\n",
    "obj = dict()\n",
    "\n",
    "assert type(path) is str\n",
    "assert type(obj) is dict\n",
    "#ogh.saveDictOfDf(outfilepath=path, dictionaryObject=obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ogh.readShapefileTable(shapefile='/home/jovyan/work/Observatory-1/tests/data/shape.shp')\n",
    "    \n",
    "if type(test) is pd.DataFrame():\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-123.53026464666088"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "path='/home/jovyan/work/Observatory-1/tests/data/shape.shp'\n",
    "test_path = gpd.read_file(path)\n",
    "lon, lat= np.array(test_path.centroid[0])\n",
    "lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONG_</th>\n",
       "      <th>ELEV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.899249</td>\n",
       "      <td>-123.530265</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         LAT       LONG_  ELEV\n",
       "0  47.899249 -123.530265   NaN"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ogh.filterPointsinShape(shape=test_poly.geometry[0], points_lat=[test_lat], points_lon=[test_lon], points_elev=None, buffer_distance=0.06, \n",
    "                        buffer_resolution=16, labels=['LAT', 'LONG_', 'ELEV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-123.530264647\n"
     ]
    }
   ],
   "source": [
    "inpath='tests/data/shape.shp'\n",
    "outpath='tests/data/test_mappingfile.csv'\n",
    "\n",
    "test_poly=gpd.read_file('/home/jovyan/work/Observatory-1/'+inpath)\n",
    "test_lon, test_lat= np.array(test_poly.centroid[0])\n",
    "\n",
    "print(test_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mapToBlock():\n",
    "    listofpoints = [point.Point([0,0])]\n",
    "    listofregions = \n",
    "\n",
    "        \n",
    "def mapToBlock(df_points, df_regions):\n",
    "    \"\"\"\n",
    "    Map block membership for each coordinate point\n",
    "    \n",
    "    df_points: (dataframe) a dataframe containing the lat and long for each time-series datafile\n",
    "    dr_regions: (dataframe) a dataframe containing the bounding box (bbox) for each block cluster\n",
    "    \"\"\"\n",
    "    \n",
    "    for index, eachblock in df_regions.iterrows():\n",
    "        for ind, row in df_points.iterrows():\n",
    "            if point.Point(row['LONG_'], row['LAT']).intersects(eachblock['bbox']):\n",
    "                df_points.loc[ind, 'blocks'] = str(eachblock['dirname'])\n",
    "    return(df_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dailymet_bclivneh2013',\n",
       " 'dailymet_livneh2013',\n",
       " 'dailymet_livneh2015',\n",
       " 'dailyvic_livneh2013',\n",
       " 'dailyvic_livneh2015',\n",
       " 'dailywrf_bcsalathe2014',\n",
       " 'dailywrf_salathe2014']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize ogh_meta\n",
    "meta_file = dict(ogh.ogh_meta())\n",
    "sorted(meta_file.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bar</th>\n",
       "      <th>foo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bar foo\n",
       "0    1   a\n",
       "1    2   b"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj1 = pd.DataFrame({'foo':['a','b'],'bar':[1,2]})\n",
    "obj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('/home/jovyan/work/Observatory-1/tests/data/shape.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "unit test: ftp source\n",
    "\"\"\"\n",
    "\n",
    "import ftplib\n",
    "\n",
    "html = 'ftp://livnehpublicstorage.colorado.edu/public/Livneh.2013.CONUS.Dataset/Fluxes.asc.v.1.2.1915.2011.bz2/fluxes.100.95.25.36/VIC_fluxes_Livneh_CONUSExt_v.1.2_2013_25.90625_-97.40625.bz2'\n",
    "\n",
    "def ftp_cataloging(html):\n",
    "    domain = html.replace('ftp://','').split('/',1)[0]\n",
    "    subdomain = html.replace('ftp://','').split('/',1)[1].rsplit('/',1)[0]\n",
    "    filename = html.rsplit('/',1)[1]\n",
    "\n",
    "    ftp=ftplib.FTP(domain)\n",
    "    ftp.login()\n",
    "    ftp.cwd(subdomain)\n",
    "    existence=len(ftp.nlst(filename))==1\n",
    "    ftp.close()\n",
    "    return(existence)\n",
    "\n",
    "ipaddress = html.replace('ftp://','').split('/',1)[0]\n",
    "path = html.replace('ftp://','').split('/',1)[1].rsplit('/',1)[0]\n",
    "\n",
    "filename = html.rsplit('/',1)[1]\n",
    "fakename = filename+str(1)\n",
    "\n",
    "ftp=ftplib.FTP(ipaddress)\n",
    "ftp.login()\n",
    "ftp.cwd(path)\n",
    "\n",
    "\n",
    "if len(ftp.nlst(filename))==1:\n",
    "    assert True\n",
    "\n",
    "if len(ftp.nlst(fakename))==0:\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cataloging the existence of target ftp files\n",
    "\n",
    "mfs=[]\n",
    "for shp, filename in zip([sauk, elwha, riosalado], \n",
    "                         ['Sauk_mappingfile.csv','Elwha_mappingfile.csv','RioSalado_mappingfile.csv']):\n",
    "    \n",
    "    obj=dask.delayed(ogh.treatgeoself)(shapefile=shp, NAmer=NAmer, buffer_distance=0.06, \n",
    "                                       mappingfile=os.path.join(os.getcwd(),filename))\n",
    "    \n",
    "mfs.append(obj)\n",
    "\n",
    "dask.visualize(mfs)\n",
    "\n",
    "\n",
    "import ftplib\n",
    "\n",
    "def ftp_cataloging(html):\n",
    "    domain = html.replace('ftp://','').split('/',1)[0]\n",
    "    subdomain = html.replace('ftp://','').split('/',1)[1].rsplit('/',1)[0]\n",
    "    filename = html.rsplit('/',1)[1]\n",
    "\n",
    "    ftp=ftplib.FTP(domain)\n",
    "    ftp.login()\n",
    "    ftp.cwd(subdomain)\n",
    "    existence=len(ftp.nlst(filename))==1\n",
    "    ftp.close()\n",
    "    return(existence)\n",
    "\n",
    "# generate table of lats and long coordinates\n",
    "maptable = pd.read_csv(mappingfile3)\n",
    "\n",
    "# compile the longitude and latitude points\n",
    "locations = ogh.compile_dailyMET_Livneh2013_locations(maptable)\n",
    "\n",
    "output = [dask.delayed(ftp_cataloging)(html) for html in locations]\n",
    "print(output)\n",
    "output2 = dask.compute(output)\n",
    "output2\n",
    "\n",
    "# Download the files\n",
    "# ftp_download_p(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ogh.getDailyMET_livneh2013(homedir, mappingfile2)\n",
    "# ogh.getDailyMET_bcLivneh2013(homedir, mappingfile2)\n",
    "# ogh.getDailyMET_livneh2015(homedir, mappingfile2)\n",
    "\n",
    "# ogh.getDailyVIC_livneh2013(homedir, mappingfile2)\n",
    "# ogh.getDailyVIC_livneh2015(homedir, mappingfile2)\n",
    "\n",
    "# ogh.getDailyWRF_salathe2014(homedir, mappingfile2)\n",
    "# ogh.getDailyWRF_bcsalathe2014(homedir, mappingfile2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "All watersheds\n",
    "\n",
    "shape_path: (dir) the path to the watershed ESRI shapefile without the .shp suffix\n",
    "espg: (int) the epsg map projection\n",
    "polygon_color: (str) the name or single-letter code for the color of the watershed polygons\n",
    "map_margins: (float) the multiplier for the map margins outside of the watershed bounding box\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "shape_path = os.path.join(homedir, 'allwatersheds')\n",
    "epsg = 3857\n",
    "polygon_color = 'm' # magenta\n",
    "map_margin = 0.25 # 25% of width and height dimensions\n",
    "mapscaleloc = 'botleft'\n",
    "\n",
    "\n",
    "# generate the figure axis\n",
    "fig = plt.figure(figsize=(3,3), dpi=500)\n",
    "ax1 = plt.subplot2grid((1,1),(0,0))\n",
    "\n",
    "# normalize the color distribution according to the value distribution\n",
    "cmap = mpl.cm.gnuplot2\n",
    "\n",
    "# calculate bounding box based on the watershed shapefile\n",
    "watershed = fiona.open(shape_path+'.shp')\n",
    "minx, miny, maxx, maxy = watershed.bounds\n",
    "w, h = maxx - minx, maxy - miny\n",
    "watershed.close()\n",
    "\n",
    "# generate basemap\n",
    "m = Basemap(projection='merc', epsg=epsg, resolution='h', ax=ax1,\n",
    "            llcrnrlon=minx - map_margin*w, llcrnrlat=miny - map_margin*h, \n",
    "            urcrnrlon=maxx + map_margin*w, urcrnrlat=maxy + map_margin*h)\n",
    "\n",
    "# affix boundaries\n",
    "m.drawcountries(linewidth=0.1)\n",
    "m.drawcoastlines(linewidth=0.1)\n",
    "m.drawmapboundary(fill_color='lightskyblue')\n",
    "m.fillcontinents(color='cornsilk', lake_color='lightskyblue')\n",
    "m.drawrivers(color='lightskyblue', linewidth=0.1)\n",
    "m.drawstates(linewidth=0.1, linestyle='solid', color='gray')\n",
    "m.drawcountries(color='gray', linewidth=0.1)\n",
    "\n",
    "# draw distance scale\n",
    "# length = round(w*50,-2)\n",
    "# yoffset = w*1000\n",
    "# m.drawmapscale(minx, miny-0.5*map_margin*h, maxx, maxy, length, yoffset=yoffset, barstyle='fancy', fontsize=3, linewidth=0)\n",
    "m.drawmapscale(minx, miny, maxx, maxy, 500, yoffset=35000, barstyle='fancy', fontsize=3, linewidth=0)\n",
    "\n",
    "# draw cardinal markers\n",
    "m.drawparallels(np.arange(10,70,10),labels=[1,0,0,0], fontsize=3, color='black', linewidth=0.5)\n",
    "m.drawmeridians(np.arange(-160,0,10),labels=[0,0,1,0], fontsize=3, color='black', linewidth=0.5)\n",
    "\n",
    "# read and transform the watershed shapefiles\n",
    "m.readshapefile(shapefile = shape_path, name='allwatersheds', linewidth=0)\n",
    "\n",
    "# load and transform each polygon in shape\n",
    "patches = [PolygonPatch(Polygon(np.array(shape)), fc=polygon_color, ec=polygon_color, linewidth=0.1, zorder=5.0) \n",
    "           for info, shape in zip(m.allwatersheds_info, m.allwatersheds)]\n",
    "\n",
    "# assimilate shapes to plot axis\n",
    "coll = PatchCollection(patches, cmap=cmap, match_original=True, zorder=5.0)\n",
    "ax1.add_collection(coll)\n",
    "\n",
    "plt.savefig(os.path.join(homedir, 'statemap.png'), dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import tarfile\n",
    "\n",
    "def tar_tree(tarfilename, source_dir):\n",
    "    with tarfile.open(tarfilename, \"w:gz\") as tar:\n",
    "        tar.add(source_dir, arcname=os.path.basename(source_dir))\n",
    "    tar.close()\n",
    "    return(tarfilename)\n",
    "\n",
    "tarlist=[]\n",
    "for folder in ['livneh2013', 'livneh2015','salathe2014']:\n",
    "    sourcepath = os.path.join(homedir, folder)\n",
    "    outfilename = sourcepath+'.tar.gz'\n",
    "    tar = dask.delayed(tar_tree)(tarfilename=outfilename, source_dir=sourcepath)\n",
    "    tarlist.append(tar)\n",
    "    \n",
    "dask.compute(tarlist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
